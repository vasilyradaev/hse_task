{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountry-convert\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/e7/26c14899a43c34e04a58e3772007afe79dbd64fac15d2fbaeedff24082f2/pycountry_convert-0.7.2-py3-none-any.whl\n",
      "Collecting pprintpp>=0.3.0 (from pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/d1/e4ed95fdd3ef13b78630280d9e9e240aeb65cc7c544ec57106149c3942fb/pprintpp-0.4.0-py2.py3-none-any.whl\n",
      "Collecting pytest-mock>=1.6.3 (from pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/fd/52de218c335039f4ac25803101d5c3337c69045c68166b969d85821e49dc/pytest_mock-3.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: pytest>=3.4.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pycountry-convert) (5.2.1)\n",
      "Collecting repoze.lru>=0.7 (from pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/30/6cc0c95f0b59ad4b3b9163bff7cdcf793cc96fac64cf398ff26271f5cf5e/repoze.lru-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.30.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pycountry-convert) (0.33.6)\n",
      "Collecting pycountry>=16.11.27.1 (from pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
      "Collecting pytest-cov>=2.5.1 (from pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/13/ae3dec587b1cc07fb9f294e52ea9ad140266aea55adb9e12eade3625bd27/pytest_cov-2.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (1.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (0.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (0.4.1)\n",
      "Collecting coverage>=4.4 (from pytest-cov>=2.5.1->pycountry-convert)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/52/44e13a8bddc40d6a9c27fbb76166de5ab80cee3707d069a33c2a1b0f9514/coverage-5.2-cp37-cp37m-win_amd64.whl (207kB)\n",
      "Requirement already satisfied: six in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from packaging->pytest>=3.4.0->pycountry-convert) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from packaging->pytest>=3.4.0->pycountry-convert) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vasily\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest>=3.4.0->pycountry-convert) (0.6.0)\n",
      "Building wheels for collected packages: pycountry\n",
      "  Building wheel for pycountry (setup.py): started\n",
      "  Building wheel for pycountry (setup.py): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746871 sha256=3aa17fb357f407c6ac3c897e6fab76966d5833f15f7ee80c616f4bb9b7593f2e\n",
      "  Stored in directory: C:\\Users\\vasily\\AppData\\Local\\pip\\Cache\\wheels\\33\\4e\\a6\\be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
      "Successfully built pycountry\n",
      "Installing collected packages: pprintpp, pytest-mock, repoze.lru, pycountry, coverage, pytest-cov, pycountry-convert\n",
      "Successfully installed coverage-5.2 pprintpp-0.4.0 pycountry-20.7.3 pycountry-convert-0.7.2 pytest-cov-2.10.0 pytest-mock-3.2.0 repoze.lru-0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#установка не самых очевидных библиотек\n",
    "pip install pycountry-convert\n",
    "pip install flatten_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "##flattening json with credits to https://towardsdatascience.com/flattening-json-objects-in-python-f5343c794b10\n",
    "from flatten_json import flatten\n",
    "import pycountry_convert \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываю файл локально(\n",
    "with open('nlp_dataset_2000_2019.json', encoding='utf-8') as f:\n",
    "    j_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#оформляем df для табло. \n",
    "not_fully_flat_df = json_normalize(j_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_index',\n",
       " '_type',\n",
       " '_id',\n",
       " '_score',\n",
       " '_source.DOI',\n",
       " '_source.issue',\n",
       " '_source.volume',\n",
       " '_source.created',\n",
       " '_source.pubdate',\n",
       " '_source.doc_type',\n",
       " '_source.page_end',\n",
       " '_source.publisher',\n",
       " '_source.book_title',\n",
       " '_source.page_start',\n",
       " '_source.citation_count',\n",
       " '_source.reference_count',\n",
       " '_source.nid',\n",
       " '_source.fields_of_study',\n",
       " '_source.fos',\n",
       " '_source.language',\n",
       " '_source.title.en',\n",
       " '_source.has_title',\n",
       " '_source.organisations',\n",
       " '_source.affiliations',\n",
       " '_source.authors',\n",
       " '_source.has_abstract',\n",
       " '_source.abstract.en',\n",
       " '_source.phrases.en.part.title.ORG',\n",
       " '_source.phrases.en.part.abstract.NP',\n",
       " '_source.phrases.en.part.abstract.ORG',\n",
       " '_source.phrases.en.model.name',\n",
       " '_source.phrases.en.model.version',\n",
       " '_source.embedding.en.bert.model',\n",
       " '_source.embedding.en.bert.vector',\n",
       " '_source.countries',\n",
       " '_source.phrases.en.part.title.NP',\n",
       " '_source.phrases.en.part.abstract.PRODUCT',\n",
       " '_source.phrases.en.part.title.GPE',\n",
       " '_source.title.es',\n",
       " '_source.phrases.en.part.abstract.GPE',\n",
       " '_source.title.pt',\n",
       " '_source.phrases.en.part.title.PERSON',\n",
       " '_source.phrases.en.part.abstract.PERSON',\n",
       " '_source.title.id',\n",
       " '_source.title.sk',\n",
       " '_source.title.tr',\n",
       " '_source.title.ms',\n",
       " '_source.phrases.en.part.title.PRODUCT',\n",
       " '_source.title.un',\n",
       " '_source.title.el',\n",
       " '_source.title.hu',\n",
       " '_source.title.cs',\n",
       " '_source.title.fr',\n",
       " '_source.title.it',\n",
       " '_source.title.ru',\n",
       " '_source.phrases.ru.part.title.NP',\n",
       " '_source.phrases.ru.model.name',\n",
       " '_source.phrases.ru.model.version',\n",
       " '_source.title.pl',\n",
       " '_source.title.zzp',\n",
       " '_source.title.ko',\n",
       " '_source.title.gl',\n",
       " '_source.title.nl',\n",
       " '_source.title.zh-Hant',\n",
       " '_source.title.ia',\n",
       " '_source.title.uk',\n",
       " '_source.title.de',\n",
       " '_source.title.ca',\n",
       " '_source.title.ja',\n",
       " '_source.title.ro',\n",
       " '_source.title.eu',\n",
       " '_source.title.la',\n",
       " '_source.title.sco',\n",
       " '_source.title.be',\n",
       " '_source.title.vi',\n",
       " '_source.title.da',\n",
       " '_source.title.hr',\n",
       " '_source.title.sv',\n",
       " '_source.title.ar',\n",
       " '_source.title.et',\n",
       " '_source.title.tlh',\n",
       " '_source.title.uz',\n",
       " '_source.title.jw',\n",
       " '_source.title.zh',\n",
       " '_source.title.bs',\n",
       " 'ranked_fos']"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(not_fully_flat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ура! Можно добавить информацию по странам для 37 наблюдений \n"
     ]
    }
   ],
   "source": [
    "#попробуем получить информацию и недостающих странах из информации об унверситетах\n",
    "#функция, проходит по списку словарей, вытаскивает из каждого код страны  заполняет ими список \n",
    "def country_getter(l):\n",
    "    c_list = []\n",
    "    for dic in l:\n",
    "        if 'country_code' in list(dic):\n",
    "            c_list.append(dic['country_code'])\n",
    "    return list(set(c_list))\n",
    "affl_countries = not_fully_flat_df['_source.affiliations'].dropna().apply(country_getter)    \n",
    "new_rows = abs(not_fully_flat_df['_source.countries'].notna().sum() - affl_countries.notna().sum())\n",
    "print(\"Ура! Можно добавить информацию по странам для {} наблюдений \".format(new_rows))\n",
    "not_fully_flat_df['_source.countries'].update(affl_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В данных по organisations и affiliations расхождений нет\n"
     ]
    }
   ],
   "source": [
    "def org_getter(l):\n",
    "    c_list = []\n",
    "    for dic in l:\n",
    "        if 'name' in list(dic):\n",
    "            c_list.append(dic['name'])\n",
    "    return list(set(c_list))\n",
    "affl_orgs = not_fully_flat_df['_source.affiliations'].dropna().apply(org_getter)\n",
    "if affl_orgs.notna().sum() == not_fully_flat_df['_source.organisations'].notna().sum(): \n",
    "    print('В данных по organisations и affiliations расхождений нет') \n",
    "#если расхождений ет, то можно и не обновлять колонку organisations.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    5504\n",
       "10    4469\n",
       "12    3629\n",
       "9     2566\n",
       "8     2265\n",
       "7     1777\n",
       "6     1310\n",
       "13     887\n",
       "5      761\n",
       "4      369\n",
       "3      135\n",
       "14      93\n",
       "2       14\n",
       "15       4\n",
       "1        2\n",
       "Name: _source.fos, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#теперь займемся fos тэгами\n",
    "#кол-во уникальных fos тэгов на 1 статью \n",
    "not_fully_flat_df['_source.fos'].apply(len).value_counts()\n",
    "#было бы удобнее, если бы это количество было единым для всех наблюдений..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer science               18701\n",
       "Artificial intelligence        12663\n",
       "Natural language processing     7974\n",
       "Text mining                     6962\n",
       "Data mining                     6933\n",
       "Machine learning                4510\n",
       "Information retrieval           3410\n",
       "Pattern recognition             2290\n",
       "Natural language                2040\n",
       "Data science                    1582\n",
       "Information extraction          1504\n",
       "Sentiment analysis              1431\n",
       "Cluster analysis                1285\n",
       "Sentence                        1163\n",
       "Artificial neural network       1161\n",
       "Semantics                       1138\n",
       "Parsing                         1064\n",
       "Syntax                          1032\n",
       "The Internet                    1005\n",
       "Social media                     997\n",
       "Name: _source.fos, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#распаковать все термины в один Series\n",
    "list_of_terms = list(not_fully_flat_df['_source.fos'])\n",
    "full_terms = pd.Series([y for x in list_of_terms for y in x])\n",
    "#топ 20 популярных терминов и их частота появления в статьях\n",
    "full_terms.value_counts().head(20)\n",
    "#то же самое одной строчкой (ОСТАВИТЬ ПОТОМ ЭТУ СТРОЧКУ)\n",
    "not_fully_flat_df['_source.fos'].explode().value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В наблюдениях содержится 12748 типов fos-тэгов\n"
     ]
    }
   ],
   "source": [
    "#При этом всего разных видов тэгов\n",
    "print('В наблюдениях содержится {} типов fos-тэгов'.format(len(full_terms.value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Biomedical text mining, Text mining, Temporal...\n",
       "1        [Biomedical text mining, Temporal annotation, ...\n",
       "2        [Text mining, Noisy text analytics, Concept mi...\n",
       "3        [Relational database, Data modeling, Relationa...\n",
       "4        [Language identification, Text mining, Natural...\n",
       "                               ...                        \n",
       "23780    [Intelligent tutoring system, Instructional de...\n",
       "23781    [Linguistics, Artificial intelligence, Art, Gr...\n",
       "23782    [Radial basis function, Fuzzy clustering, Fuzz...\n",
       "23783    [Lexical function, Meaning–text theory, Humani...\n",
       "23784    [Linea, Art, Machine learning, Artificial inte...\n",
       "Name: _source.fields_of_study, Length: 23785, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Представляется, что в данных слишком много разных fos-тэгов (в половину от кол-ва наблюдений!), кроме того для разных\n",
    "#наблюдений их разное количество\n",
    "#Можно попробовать оставить 4 наиболее значимых (относительно критерия score) тэга и проверить повлияет ли это на конечное их\n",
    "#распределение\n",
    "#фукнция оставлет в поле fields_of_study отсортированй по значению score словарь тэгов и возвращает топ-4 тега (ключи словаря)\n",
    "def fos_rank(l):\n",
    "    rank = {}\n",
    "    for dic in l:\n",
    "        rank[dic['name']] = dic['score']\n",
    "    rank = {x: y for x, y in sorted(rank.items(), key = lambda x: x[1], reverse = True)[0:4]}\n",
    "    return list(rank)\n",
    "not_fully_flat_df['_source.fields_of_study'].apply(fos_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#добавим значения отдельной колонкой, чтобы проверить, изменятся ли результаты распределния тегов\n",
    "not_fully_flat_df['ranked_fos'] = not_fully_flat_df['_source.fields_of_study'].apply(fos_rank)\n",
    "#Для каждого наблюдения в таблице сейчас только 4 самых популярных тэга!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text mining                       5522\n",
       "Natural language processing       1893\n",
       "Data mining                       1353\n",
       "Sentiment analysis                1320\n",
       "Information extraction            1213\n",
       "Natural language                  1117\n",
       "Computer science                  1052\n",
       "Cluster analysis                   932\n",
       "Machine translation                747\n",
       "Artificial neural network          742\n",
       "Deep learning                      732\n",
       "Question answering                 707\n",
       "Machine learning                   654\n",
       "Parsing                            644\n",
       "Sentence                           628\n",
       "Information retrieval              599\n",
       "Automatic summarization            582\n",
       "Knowledge extraction               562\n",
       "Named-entity recognition           560\n",
       "Ontology (information science)     555\n",
       "Social media                       526\n",
       "Semantics                          522\n",
       "Semantic similarity                508\n",
       "The Internet                       488\n",
       "Annotation                         468\n",
       "Data science                       424\n",
       "Biomedical text mining             416\n",
       "Syntax                             410\n",
       "Semantic computing                 401\n",
       "Feature extraction                 398\n",
       "Name: ranked_fos, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#распаковать все термины в один Series\n",
    "list_of_ranked_terms = list(not_fully_flat_df['ranked_fos'])\n",
    "full_terms_ranked = pd.Series([y for x in list_of_ranked_terms for y in x])\n",
    "#топ 20 популярных терминов и их частота появления в статьях\n",
    "full_terms_ranked.value_counts().head(20)\n",
    "#одной строкой (ее остаивить)\n",
    "not_fully_flat_df['ranked_fos'].explode().value_counts().head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В наблюдениях содержится 8846 типов fos-тэгов\n"
     ]
    }
   ],
   "source": [
    "print('В наблюдениях содержится {} типов fos-тэгов'.format(len(full_terms_ranked.value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text mining                       5522\n",
       "Natural language processing       1893\n",
       "Data mining                       1353\n",
       "Sentiment analysis                1320\n",
       "Information extraction            1213\n",
       "Natural language                  1117\n",
       "Computer science                  1052\n",
       "Cluster analysis                   932\n",
       "Machine translation                747\n",
       "Artificial neural network          742\n",
       "Deep learning                      732\n",
       "Question answering                 707\n",
       "Machine learning                   654\n",
       "Parsing                            644\n",
       "Sentence                           628\n",
       "Information retrieval              599\n",
       "Automatic summarization            582\n",
       "Knowledge extraction               562\n",
       "Named-entity recognition           560\n",
       "Ontology (information science)     555\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Количество уникальных тегов изменилось несильно (на 4 тысячи тегов, для тенденций это не будет играть роли)\n",
    "#Однако распределение тегов заметно изменилось, теперь в топе тэги, который в большей степени напрямую связаны с NLP и \n",
    "#обработкой текстов \n",
    "#В итоговую таблицу занесем обе колонки (отражированные и нет)\n",
    "full_terms_ranked.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оставим те тэги, из 50 наиболее популярных, которые напрямую могут быть связаны с обработкой текстовой информации\n",
    "NLP_related_tags = ['Text mining', 'Natural language processing', 'Sentiment analysis', 'Information extraction', \n",
    "                        'Natural language', 'Machine translation', 'Question answering', 'Parsing', 'Sentence', \n",
    "                        'Information retrieval', 'Knowledge extraction', 'Named-entity recognition', 'Social media', \n",
    "                        'Semantics', 'Semantic similarity', 'Biomedical text mining', 'Semantic computing', 'Syntax', \n",
    "                        'Computational linguistics', 'WordNet','Language identification', 'Social network', 'Language model', \n",
    "                        'Pattern recognition', 'Web mining','Word embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19275 работ содержат Топ NLP-related теги\n"
     ]
    }
   ],
   "source": [
    "#проверим в каких работах содержатся эти теги и отмаркируем их как NLP related papers\n",
    "#проверим входит ли какой либо из популярных NLP тегов в теги каждой работы (так как мы представляет каждый набор тегов \n",
    "#единой строкой, то можно будет \"поймать\" дополнтельные теги, состоящие из одного из слов искомого тэга, т.е. будет True,\n",
    "#если среди тегов работы окажется не только Social media, но и, например, Social media mining ). Проверять будем по исходной\n",
    "#колонке с тегами (неотранжированной, там инфы больше)\n",
    "not_fully_flat_df['_source.fos'].apply(' '.join).str.contains('|'.join(NLP_related_tags))\n",
    "paper_has_tag = not_fully_flat_df['_source.fos'].apply(' '.join).str.contains('|'.join(NLP_related_tags)).sum()\n",
    "print('{} работ содержат Топ NLP-related теги'.format(paper_has_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "превышение на 52 работы. Ничего страшного\n"
     ]
    }
   ],
   "source": [
    "#Проверим, не слишком ли вольно мы добавляли теги? Теперь True будет только в случае, только если среди тегов работы\n",
    "#имеется любой один тег из списка Fos_NLP_tags (но условный Social media mining уже не пройдет)\n",
    "#Проссумируем количество индексов, для которых истинно, что среди списка тегов этой работы, есть один из тегов спписка\n",
    "#NLP_related_tags\n",
    "tag_diff = len(set(not_fully_flat_df['_source.fos'].explode().isin(NLP_related_tags)[not_fully_flat_df['_source.fos']\n",
    "                                         .explode().isin(NLP_related_tags)].index))\n",
    "if paper_has_tag - tag_diff < 150:\n",
    "    print('превышение на {} работы. Ничего страшного'.format(paper_has_tag - tag_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавим новую колонку в df, 1 если для работы указан один из тегов, 0 - если нет (будем использовать первое из условий)\n",
    "not_fully_flat_df['nlp_related_paper'] = not_fully_flat_df['_source.fos'] \\\n",
    "                                       .apply(' '.join).str.contains('|'.join(NLP_related_tags)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Теперь добавим аналогичную колонку только для тех работ, среди тегов которых есть Natural language (processing) и \n",
    "#Text mining\n",
    "NLP_tags = ['Natural language','Text mining']\n",
    "not_fully_flat_df['_source.fos'].apply(' '.join).str.contains('|'.join(NLP_tags)).sum()\n",
    "#Использовав тег Natural language вместо Natural language processing мы дополнительно поймали порядка 700 работ, ура. \n",
    "#Код не прописываю, можно проверить добавив слово processing в словарь NLP_tags\n",
    "not_fully_flat_df['nlp_paper'] = not_fully_flat_df['_source.fos'] \\\n",
    "                                 .apply(' '.join).str.contains('|'.join(NLP_tags)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно сделать еще более жесткий критерий, и искать теги NLP и Text mining только среди отсортированных fos тегов \n",
    "not_fully_flat_df['ranked_fos'].apply(' '.join).str.contains('|'.join(NLP_tags)).sum()\n",
    "not_fully_flat_df['total_nlp_paper'] = not_fully_flat_df['ranked_fos'] \\\n",
    "                                       .apply(' '.join).str.contains('|'.join(NLP_tags)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавим также отранжированные по встречаемости (count) именные группы, извлеченные из эбстрактов работ. Извлеченные группы из \n",
    "#названий добавлять не будем, так как они доступны только для 21500 работ \n",
    "#(not_fully_flat_df['_source.phrases.en.part.title.NP'].notna().sum())\n",
    "#а информация из эбстракта есть почти для всех (23511, not_fully_flat_df['_source.phrases.en.part.abstract.NP'].notna().sum())\n",
    "def abs_rank(l):\n",
    "    rank = {}\n",
    "    for dic in l:\n",
    "        rank[dic['term']] = dic['count']\n",
    "    rank = {x: y for x, y in sorted(rank.items(), key = lambda x: x[1], reverse = True)[0:4]}\n",
    "    return list(rank)\n",
    "not_fully_flat_df['abstract4'] = not_fully_flat_df['_source.phrases.en.part.abstract.NP'] \\\n",
    "                                          .map(abs_rank, na_action = 'ignore')\n",
    "#добавили колонку для 4 наиболее встречающихся фраз из эбстракта (или для 4 случайных фраз, если score одинаковый)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В среднем для каждой работы 93.03 ключевых фраз из эбстракта\n"
     ]
    }
   ],
   "source": [
    "#Хотя здесь мы потеряем много информации (но анализировать и искать тренды будет проще)\n",
    "sr = pd.Series([int(i) for i in list(not_fully_flat_df['_source.phrases.en.part.abstract.NP']\n",
    "                                .dropna().apply(len).value_counts().index)]).mean()\n",
    "print('В среднем для каждой работы {:.2f} ключевых фраз из эбстракта'.format(sr))\n",
    "#добавим колонку с 20 ключевыми фразами, на всякий случай\n",
    "def abs_rank(l):\n",
    "    rank = {}\n",
    "    for dic in l:\n",
    "        rank[dic['term']] = dic['count']\n",
    "    rank = {x: y for x, y in sorted(rank.items(), key = lambda x: x[1], reverse = True)[0:20]}\n",
    "    return list(rank)\n",
    "not_fully_flat_df['abstract20'] = not_fully_flat_df['_source.phrases.en.part.abstract.NP'] \\\n",
    "                                          .map(abs_rank, na_action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем сразу для самой популярной фразы в эбстракте, возможно это самая полезная информация здесь.\n",
    "def abs_rank(l):\n",
    "    rank = {}\n",
    "    for dic in l:\n",
    "        rank[dic['term']] = dic['count']\n",
    "    rank = {x: y for x, y in sorted(rank.items(), key = lambda x: x[1], reverse = True)[0:1]}\n",
    "    return list(rank)\n",
    "not_fully_flat_df['abstract'] = not_fully_flat_df['_source.phrases.en.part.abstract.NP'] \\\n",
    "                                          .map(abs_rank, na_action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Работы в среднем писалась в 1.31 странах\n",
      "Работы в среднем писалась 3.21 ученым\n",
      "Работы в среднем писалась 1.76 организациями\n"
     ]
    }
   ],
   "source": [
    "#теперь попробуем скорректировать информацию по странам/ученым/организациям\n",
    "#сколько в среднем стран, организаций и ученых принимали участие в написании одной работы  \n",
    "print('Работы в среднем писалась в {:.2f} странах'.\n",
    "      format(not_fully_flat_df['_source.countries'].map(len, na_action = 'ignore').mean()))\n",
    "print('Работы в среднем писалась {:.2f} ученым'.\n",
    "      format(not_fully_flat_df['_source.authors'].map(len, na_action = 'ignore').mean()))\n",
    "print('Работы в среднем писалась {:.2f} организациями'.\n",
    "      format(not_fully_flat_df['_source.organisations'].map(len, na_action = 'ignore').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_source.countries</th>\n",
       "      <th>_source.authors</th>\n",
       "      <th>_source.organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14971.0</td>\n",
       "      <td>2357</td>\n",
       "      <td>10534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3863.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>5935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>720.0</td>\n",
       "      <td>5053</td>\n",
       "      <td>2252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3443</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1878</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _source.countries  _source.authors  _source.organisations\n",
       "1             14971.0             2357                10534.0\n",
       "2              3863.0             4962                 5935.0\n",
       "3               720.0             5053                 2252.0\n",
       "4                96.0             3443                  732.0\n",
       "5                 NaN             1878                  197.0\n",
       "6                 NaN              934                    NaN\n",
       "7                 NaN              481                    NaN\n",
       "8                 NaN              277                    NaN\n",
       "9                 NaN              164                    NaN\n",
       "10                NaN              101                    NaN"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#как много стран/ученых/организаций принимали участие в написании работ\n",
    "not_fully_flat_df[['_source.countries', '_source.authors', '_source.organisations']] \\\n",
    "                .dropna().applymap(len).apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Большинство работ выполнялись в рамках 1-4 стран коллективом из 1-10 ученых внутри 1-5 организаций.\n",
    "#Данные об остальных работах (стран > 4, ученых > 10 и организаций > 5) представляется возможным убрать, это позволит упростить \n",
    "#структуру данных, на результат повлияет незначительно (отдельно можно рассмотреть выбросы, изучить, что за работы связаны\n",
    "#с участием 85 ученых или широкого участия стран/ученых/организаций)\n",
    "#Видимо на предыдущем шаге при добавлении стран из affiliations просто добавились нулевые значения(( удалим им тоже\n",
    "#Сделаем копию исходника пржде чем удалять \n",
    "not_fully_flat_df_copy = not_fully_flat_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 наблюдения удалены\n"
     ]
    }
   ],
   "source": [
    "#удалим работы с кол-вом стран > 4\n",
    "drop_country_index = not_fully_flat_df['_source.countries'] \\\n",
    "                     [not_fully_flat_df['_source.countries'].map(len, na_action = 'ignore') > 4 ].index\n",
    "drop_country_index = drop_country_index.append(not_fully_flat_df['_source.countries'] \\\n",
    "                     [not_fully_flat_df['_source.countries'].map(len, na_action = 'ignore') == 0 ].index)\n",
    "print('{} наблюдения удалены'.format(len(drop_country_index)))\n",
    "not_fully_flat_df.drop(drop_country_index, inplace = True)\n",
    "#пересчитаем индексы\n",
    "not_fully_flat_df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 наблюдений удалено\n"
     ]
    }
   ],
   "source": [
    "#удалим работы с кол-вом ученых > 10\n",
    "drop_author_index = not_fully_flat_df['_source.authors'] \\\n",
    "                    [not_fully_flat_df['_source.authors'].map(len, na_action = 'ignore') > 10].index\n",
    "print('{} наблюдений удалено'.format(len(drop_author_index)))\n",
    "not_fully_flat_df.drop(drop_author_index, inplace = True)\n",
    "not_fully_flat_df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 наблюдений удалено\n"
     ]
    }
   ],
   "source": [
    "#удалим работы с кол-вом организаций > 5\n",
    "drop_organisation_index = not_fully_flat_df['_source.organisations'] \\\n",
    "                          [not_fully_flat_df['_source.organisations'].map(len, na_action = 'ignore') > 5].index\n",
    "print('{} наблюдений удалено'.format(len(drop_organisation_index)))\n",
    "not_fully_flat_df.drop(drop_organisation_index, inplace = True)\n",
    "not_fully_flat_df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верно, было удалено 410 наблюдения\n"
     ]
    }
   ],
   "source": [
    "#сверим длину таблиц (начальной/конечной)\n",
    "sum_deleted = len(drop_author_index) + len(drop_country_index) + len(drop_organisation_index)\n",
    "if len(not_fully_flat_df) + sum_deleted == len(not_fully_flat_df_copy):\n",
    "    print(\"Верно, было удалено {} наблюдений\".format(sum_deleted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_source.countries</th>\n",
       "      <th>_source.authors</th>\n",
       "      <th>_source.organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14971.0</td>\n",
       "      <td>2357</td>\n",
       "      <td>10534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3863.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>5935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>720.0</td>\n",
       "      <td>5053</td>\n",
       "      <td>2252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3443</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1878</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _source.countries  _source.authors  _source.organisations\n",
       "1             14971.0             2357                10534.0\n",
       "2              3863.0             4962                 5935.0\n",
       "3               720.0             5053                 2252.0\n",
       "4                96.0             3443                  732.0\n",
       "5                 NaN             1878                  197.0\n",
       "6                 NaN              934                    NaN\n",
       "7                 NaN              481                    NaN\n",
       "8                 NaN              277                    NaN\n",
       "9                 NaN              164                    NaN\n",
       "10                NaN              101                    NaN"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверим по таблице\n",
    "not_fully_flat_df[['_source.countries', '_source.authors', '_source.organisations']] \\\n",
    "                .dropna().applymap(len).apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данные для табло (пока что без abstract20 и без abstract4, табло будет ругаться )\n",
    "tableau_data = not_fully_flat_df[['_id', '_source.pubdate', '_source.doc_type','_source.publisher',\n",
    "                                  '_source.citation_count', '_source.reference_count', '_source.organisations', \n",
    "                                  '_source.authors', '_source.countries', 'ranked_fos','nlp_related_paper', 'nlp_paper',\n",
    "                                  'abstract', '_source.fos','total_nlp_paper']]\\\n",
    "               .rename(columns = {'_id':'id', '_source.pubdate':'pubdate', \n",
    "                                  '_source.doc_type':'doc_type', '_source.publisher':'publisher',\n",
    "                                  '_source.citation_count':'citations', '_source.reference_count':'references', \n",
    "                                  '_source.organisations':'organisations', '_source.authors':'authors', \n",
    "                                  '_source.countries':'countries', '_source.fos':'fos'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем локальный файл для загрузки в табло (нужно будет заменить на свой путь; это можно сделать красивее, конечно)))\n",
    "tableau_data.to_json('C:/Users/vasily/Studies/nlp_dataset_2000_2019_1.json', orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#это я думал как бы лучше загрузить файл в табло и полностью разворичивал словари из словарей в один большой df\n",
    "#Из интересного ниже информация о публикациях на разных языках\n",
    "#flattened nested data\n",
    "flat_data = [flatten(i) for i in j_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put into df, получаем полностью разверутый дф\n",
    "flat_df = pd.DataFrame(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#перевести даты в падас формат\n",
    "flat_df['year'] = pd.DatetimeIndex(flat_df['_source_pubdate']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pub_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2013</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2014</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>2647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2019</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  pub_num\n",
       "0   2000      241\n",
       "1   2001      216\n",
       "2   2002      318\n",
       "3   2003      332\n",
       "4   2004      477\n",
       "5   2005      585\n",
       "6   2006      673\n",
       "7   2007      789\n",
       "8   2008      901\n",
       "9   2009      985\n",
       "10  2010     1196\n",
       "11  2011     1186\n",
       "12  2012     1448\n",
       "13  2013     1649\n",
       "14  2014     1861\n",
       "15  2015     2055\n",
       "16  2016     2117\n",
       "17  2017     2261\n",
       "18  2018     2647\n",
       "19  2019     1848"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#колво публикаций в году\n",
    "flat_df.groupby('year', as_index = False).aggregate({'_index': 'count'}).rename(columns = {'_index':'pub_num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_source_countries_0</th>\n",
       "      <th>pub_in_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>US</td>\n",
       "      <td>5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>CN</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>IN</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>GB</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>DE</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>UY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>MW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>MD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>ME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>JM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _source_countries_0  pub_in_country\n",
       "113                  US            5459\n",
       "20                   CN            2389\n",
       "48                   IN            1149\n",
       "36                   GB            1136\n",
       "26                   DE             838\n",
       "..                  ...             ...\n",
       "114                  UY               1\n",
       "77                   MW               1\n",
       "69                   MD               1\n",
       "70                   ME               1\n",
       "53                   JM               1\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#поиск публикаций по странам в развернутом df\n",
    "countries0 = flat_df\\\n",
    "    .groupby('_source_countries_0', as_index = False)\\\n",
    "    .agg({'_index':'count'}) \\\n",
    "    .rename(columns = {'_index':'pub_in_country'})\\\n",
    "    .sort_values(by = 'pub_in_country', ascending = False)\n",
    "countries0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 publications in de\n",
      "There are 15 publications in nt\n",
      "There are 20 publications in ru\n",
      "There are 24 publications in el\n",
      "There are 41 publications in id\n",
      "There are 63 publications in pt\n",
      "There are 67 publications in fr\n",
      "There are 72 publications in es\n",
      "There are 76 publications in ko\n",
      "There are 166 publications in un\n",
      "There are 23138 publications in en\n"
     ]
    }
   ],
   "source": [
    "#про языки.\n",
    "#количество публикаций на разных языках\n",
    "lang_col_list = (list(flat_df.filter(like = '_source_title_', axis = 1)))\n",
    "#колво публикаций а разных языках\n",
    "lang_dict = {}\n",
    "for el in lang_col_list:\n",
    "    lang_dict[el[-2:]] = len(flat_df) - flat_df[el].isnull().sum()\n",
    "#отсортированный список с языками\n",
    "sort_lang_dict = sorted(lang_dict.items(), key = lambda x : x[1])\n",
    "for el in sort_lang_dict:\n",
    "    if el[1] > 10:\n",
    "        print('There are {} publications in {}'.format(el[1], el[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_type</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>_source_DOI</th>\n",
       "      <th>_source_issue</th>\n",
       "      <th>_source_volume</th>\n",
       "      <th>_source_created</th>\n",
       "      <th>_source_pubdate</th>\n",
       "      <th>_source_doc_type</th>\n",
       "      <th>...</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_127_term</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_128_count</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_128_term</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_129_count</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_129_term</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_130_count</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_130_term</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_131_count</th>\n",
       "      <th>_source_phrases_en_part_abstract_PERSON_131_term</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10456</td>\n",
       "      <td>sti_science_mag_v1.0.2</td>\n",
       "      <td>_doc</td>\n",
       "      <td>2157414955</td>\n",
       "      <td>12.106363</td>\n",
       "      <td>10.1186/2041-1480-5-5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _index _type         _id     _score  \\\n",
       "10456  sti_science_mag_v1.0.2  _doc  2157414955  12.106363   \n",
       "\n",
       "                 _source_DOI _source_issue _source_volume _source_created  \\\n",
       "10456  10.1186/2041-1480-5-5             1              5      2016-06-24   \n",
       "\n",
       "      _source_pubdate _source_doc_type  ...  \\\n",
       "10456      2014-01-01  journal-article  ...   \n",
       "\n",
       "      _source_phrases_en_part_abstract_PERSON_127_term  \\\n",
       "10456                                              NaN   \n",
       "\n",
       "      _source_phrases_en_part_abstract_PERSON_128_count  \\\n",
       "10456                                               NaN   \n",
       "\n",
       "      _source_phrases_en_part_abstract_PERSON_128_term  \\\n",
       "10456                                              NaN   \n",
       "\n",
       "      _source_phrases_en_part_abstract_PERSON_129_count  \\\n",
       "10456                                               NaN   \n",
       "\n",
       "       _source_phrases_en_part_abstract_PERSON_129_term  \\\n",
       "10456                                               NaN   \n",
       "\n",
       "       _source_phrases_en_part_abstract_PERSON_130_count  \\\n",
       "10456                                                NaN   \n",
       "\n",
       "       _source_phrases_en_part_abstract_PERSON_130_term  \\\n",
       "10456                                               NaN   \n",
       "\n",
       "       _source_phrases_en_part_abstract_PERSON_131_count  \\\n",
       "10456                                                NaN   \n",
       "\n",
       "       _source_phrases_en_part_abstract_PERSON_131_term  year  \n",
       "10456                                               NaN  2014  \n",
       "\n",
       "[1 rows x 2399 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Это аблюдений интересно тем, что в написании этой работы приняли участие 85 человек, видимо это крупная конференция)\n",
    "full_col_list = list(flat_df)\n",
    "flat_df[flat_df['_source_authors_84'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#считаем сколько раз встречается то или иное значение в таблице (про имена ученых; да про все что угодно)\n",
    "flat_df[list(flat_df)].apply(lambda s: (s == 'Iryna Gurevych').sum(), axis=1).sum()\n",
    "#аналогично, чуть быстрее \n",
    "#(flat_df[list(flat_df)] == 'Hongfang Liu').sum(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ru_ft_syntagrus_md    20\n",
       "Name: _source.phrases.ru.model.name, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20 работ на русском языке единственные из всей базы (23850 работ), для которых указана собственная nlp модель!\n",
    "not_fully_flat_df['_source.phrases.ru.model.name'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
